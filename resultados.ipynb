{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias necesarias\n",
    "import os\n",
    "\n",
    "# Matplotlib conf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (15, 5),\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':40,\n",
    "         'ytick.labelsize': 40\n",
    "}\n",
    "plt.rcParams.update(params)\n",
    "# Seaborn conf\n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid')\n",
    "sns.set_palette(sns.color_palette(\"Blues\"))\n",
    "\n",
    "import sys\n",
    "\n",
    "#Procesado de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "#Modelos\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from nltk import ngrams\n",
    "\n",
    "from keras.layers import Dense, Embedding, Flatten, GlobalMaxPool1D, Dropout\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from keras.initializers import Constant\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from nltk import ngrams\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "#si no queremos ver los warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_csv_all_experiment(number_of_experiments):\n",
    "    experiments_data = []\n",
    "    for i in range(1, number_of_experiments+1):\n",
    "        experiments_data.append( pd.read_csv(\"exp_0\"+str(i)+\".csv\") )\n",
    "\n",
    "    res = pd.concat(experiments_data, ignore_index=True)\n",
    "    res.to_csv(\"exp_all.csv\", index=False)\n",
    "\n",
    "join_csv_all_experiment(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>rep.model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Exp08BERT epochs=2 data=raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.947191</td>\n",
       "      <td>0.945000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Exp08BERT epochs=1 data=raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.941485</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Exp08BERT epochs=3 data=raw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.938500</td>\n",
       "      <td>0.938521</td>\n",
       "      <td>0.938500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exp06GRU layers_units=[128],extra_dense_layer_...</td>\n",
       "      <td>Word embedding with GloVe</td>\n",
       "      <td>0.908363</td>\n",
       "      <td>0.908811</td>\n",
       "      <td>0.908363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Exp06GRU layers_units=[8],extra_dense_layer_nn...</td>\n",
       "      <td>Word embedding with GloVe</td>\n",
       "      <td>0.902354</td>\n",
       "      <td>0.903327</td>\n",
       "      <td>0.902354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          classifier  \\\n",
       "0                        Exp08BERT epochs=2 data=raw   \n",
       "1                        Exp08BERT epochs=1 data=raw   \n",
       "2                        Exp08BERT epochs=3 data=raw   \n",
       "3  Exp06GRU layers_units=[128],extra_dense_layer_...   \n",
       "4  Exp06GRU layers_units=[8],extra_dense_layer_nn...   \n",
       "\n",
       "                   rep.model  accuracy  precision    recall  \n",
       "0                        NaN  0.945000   0.947191  0.945000  \n",
       "1                        NaN  0.940000   0.941485  0.940000  \n",
       "2                        NaN  0.938500   0.938521  0.938500  \n",
       "3  Word embedding with GloVe  0.908363   0.908811  0.908363  \n",
       "4  Word embedding with GloVe  0.902354   0.903327  0.902354  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosa = pd.read_csv(\"exp_all.csv\").sort_values(by=[\"accuracy\"], ascending=False, ignore_index=True)[[\"classifier\", \"rep.model\", \"accuracy\",\"precision\",\"recall\"]]\n",
    "cosa.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>rep.model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Exp05StackedRNN layers_units=[2,2],extra_dense...</td>\n",
       "      <td>Word embedding: tokenizando el texto en secuen...</td>\n",
       "      <td>0.562344</td>\n",
       "      <td>0.570067</td>\n",
       "      <td>0.562344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Exp06GRU layers_units=[64],extra_dense_layer_n...</td>\n",
       "      <td>VSM + pesado TF-IDF + rango de n-grams [1 y 2]...</td>\n",
       "      <td>0.499750</td>\n",
       "      <td>0.249750</td>\n",
       "      <td>0.499750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>Exp06GRU layers_units=[64],extra_dense_layer_n...</td>\n",
       "      <td>VSM + pesado binario + rango de n-grams [1 y 2...</td>\n",
       "      <td>0.499750</td>\n",
       "      <td>0.249750</td>\n",
       "      <td>0.499750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>Exp06GRU layers_units=[64],extra_dense_layer_n...</td>\n",
       "      <td>VSM + pesado TF-IDF + redimensionamiento por S...</td>\n",
       "      <td>0.499750</td>\n",
       "      <td>0.249750</td>\n",
       "      <td>0.499750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>Exp06GRU layers_units=[64],extra_dense_layer_n...</td>\n",
       "      <td>VSM + pesado binario + redimensionamiento por ...</td>\n",
       "      <td>0.499750</td>\n",
       "      <td>0.249750</td>\n",
       "      <td>0.499750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            classifier  \\\n",
       "298  Exp05StackedRNN layers_units=[2,2],extra_dense...   \n",
       "299  Exp06GRU layers_units=[64],extra_dense_layer_n...   \n",
       "300  Exp06GRU layers_units=[64],extra_dense_layer_n...   \n",
       "301  Exp06GRU layers_units=[64],extra_dense_layer_n...   \n",
       "302  Exp06GRU layers_units=[64],extra_dense_layer_n...   \n",
       "\n",
       "                                             rep.model  accuracy  precision  \\\n",
       "298  Word embedding: tokenizando el texto en secuen...  0.562344   0.570067   \n",
       "299  VSM + pesado TF-IDF + rango de n-grams [1 y 2]...  0.499750   0.249750   \n",
       "300  VSM + pesado binario + rango de n-grams [1 y 2...  0.499750   0.249750   \n",
       "301  VSM + pesado TF-IDF + redimensionamiento por S...  0.499750   0.249750   \n",
       "302  VSM + pesado binario + redimensionamiento por ...  0.499750   0.249750   \n",
       "\n",
       "       recall  \n",
       "298  0.562344  \n",
       "299  0.499750  \n",
       "300  0.499750  \n",
       "301  0.499750  \n",
       "302  0.499750  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosa.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportar a LATEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "classifier & rep.model & accuracy & precision & recall \\\\\n",
      "\\midrule\n",
      "Exp08BERT epochs=2 data=raw & nan & 0.94 & 0.95 & 0.94 \\\\\n",
      "Exp08BERT epochs=1 data=raw & nan & 0.94 & 0.94 & 0.94 \\\\\n",
      "Exp08BERT epochs=3 data=raw & nan & 0.94 & 0.94 & 0.94 \\\\\n",
      "Exp08BERT epochs=3 data=PREPROCESSED & nan & 0.9 & 0.9 & 0.9 \\\\\n",
      "Exp08BERT epochs=1 data=PREPROCESSED & nan & 0.89 & 0.89 & 0.89 \\\\\n",
      "Exp08BERT epochs=2 data=PREPROCESSED & nan & 0.89 & 0.89 & 0.89 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cosa = pd.read_csv(\"exp_08.csv\").sort_values(by=[\"accuracy\"], ascending=False, ignore_index=True)[[\"classifier\", \"rep.model\", \"accuracy\",\"precision\",\"recall\"]]\n",
    "cosa[\"classifier\"] = cosa[\"classifier\"].str.replace(',', \", \")\n",
    "cosa = cosa.round(2).astype(str)\n",
    "print( cosa.to_latex(escape=True, index=False) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosa = pd.read_csv(\"exp_all.csv\").sort_values(by=[\"accuracy\"], ascending=False, ignore_index=True)[[\"classifier\", \"rep.model\", \"accuracy\",\"precision\",\"recall\"]]\n",
    "cosa[\"classifier\"] = cosa[\"classifier\"].str.replace(',', \", \")\n",
    "cosa = cosa.round(2).astype(str)\n",
    "with open(\"exp_all.tex\", \"w\") as file:\n",
    "    file.write( cosa.to_latex(escape=True, index=False) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
